{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2dd2f4-0866-4b65-b496-5a586833eeb3",
   "metadata": {},
   "source": [
    "### TC4034.10 Análisis de grandes volúmenes de datos\n",
    "\n",
    "#### Equipo 13\n",
    "\n",
    "\n",
    "* Hansel Zapiain Rodríguez (A00469031)\n",
    "* Miguel Guillermo Galindo Orozco (A01793695)\n",
    "* Francisco José Arellano Montes (A01794283)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a4743-734c-478b-9ef4-ca1f04c0bcc2",
   "metadata": {},
   "source": [
    "**9.5 Avance de proyecto 4: Sistema de Recomendación**\n",
    "   \n",
    "Junio 2024\n",
    "\n",
    "**Objetivos**\n",
    "\n",
    "\n",
    "El desarrollo de esta actividad contribuye al cumplimiento de los objetivos del Modulo 5:\n",
    "\n",
    "Aplicar algoritmos de machine learning a big data enfocado al modelado predictivo y toma de decisiones basada en datos.\n",
    "Identificar la intersección entre Big Data e Inteligencia Artificial.\n",
    "Reconocer la aplicación de algoritmos de machine learning en el análisis de Big Data\n",
    "\n",
    "**Insciones**\n",
    "\n",
    "\n",
    "onesEn esta entrega es necesario realizar un reporte donde se enlisten los siguientes aspectos:\n",
    "\n",
    "Implementación final de sistemas de recomendación. Integra la evidencia en GitHub de los algoritmos desarrollados en los avances 4.2 y/o 6.2.\n",
    "Evaluación integral del desempeño de los modelos utilizando varias métricas. Recuerda integrar la evidencia en el repositorio GitHub del equipo.\n",
    "Documentación del código base y algoritmos implementados. Entregar en el documento word/pdf en Canvas.po)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761dcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import findspark\n",
    "import implicit\n",
    "import cudf\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit, udf, expr, row_number, collect_set\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Normalizer\n",
    "from pyspark.ml.linalg import Vectors, DenseVector\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('McAuley-Lab/Amazon-Reviews-2023', 'raw_review_All_Beauty', download_mode='force_redownload', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35078d0b-f76a-4293-b71b-aca8105179bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amz = dataset['full'].to_pandas()\n",
    "df_amz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf77eb-36d6-47b1-8dee-6f38c6dc27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.DataFrame.from_pandas(df_amz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9314b-ac31-4f2c-862a-4a3d773683f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_result = gdf.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25c6d0-8604-4db7-a364-b412c95d1a88",
   "metadata": {},
   "source": [
    "## Pyspark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cfff7-8a3d-4457-84b1-b540af4d4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "log4j_properties = '/app/config/log4j.properties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('Amazon Reviews Recommender with GPU') \\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', 'true') \\\n",
    "    .config('spark.driver.memory', '16g') \\\n",
    "    .config('spark.executor.memory', '16g') \\\n",
    "    .config('spark.sql.shuffle.partitions', '200') \\\n",
    "    .config('spark.memory.fraction', '0.8') \\\n",
    "    .config('spark.memory.storageFraction', '0.5') \\\n",
    "    .config('spark.master', 'local[*]') \\\n",
    "    .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n",
    "    .config('spark.driver.extraJavaOptions', f'-Dlog4j.configuration=file:{log4j_properties}') \\\n",
    "    .config('spark.executor.extraJavaOptions', f'-Dlog4j.configuration=file:{log4j_properties}') \\\n",
    "    .config('spark.kryoserializer.buffer.max', '2024m') \\\n",
    "    .config('spark.broadcast.compress', 'true') \\\n",
    "    .config('spark.shuffle.compress', 'true') \\\n",
    "    .config('spark.shuffle.spill.compress', 'true') \\\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', -1) \\\n",
    "    .getOrCreate()\n",
    "print('Spark Session Created:', spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021dbe9-667c-4acb-bcef-9f0d4e503475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dff136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amz_spark = pdf_result.sample(frac = 0.10, replace = False, random_state = 1234)\n",
    "df_amz_spark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2539583",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df_amz_spark[['user_id', 'asin', 'rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a809031",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.select(col('user_id').alias('user_id'), col('asin').alias('asin'), col('rating').alias('rating'))\n",
    "\n",
    "user_indexer = StringIndexer(inputCol = 'user_id', outputCol = 'userIndex')\n",
    "item_indexer = StringIndexer(inputCol = 'asin', outputCol = 'itemIndex')\n",
    "\n",
    "indexed_df = user_indexer.fit(spark_df).transform(spark_df)\n",
    "indexed_df = item_indexer.fit(indexed_df).transform(indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d049c3-6cf3-4858-a575-cc80251dbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.select('user_id').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3f19a-9c39-4997-9ce0-1e3736d7fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a8d4b-c547-459e-9925-5e89d13cbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ac399-4077-4b78-84b7-08b3f0289d21",
   "metadata": {},
   "source": [
    "## ALS (PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_df, test_df) = indexed_df.randomSplit([0.8, 0.2])\n",
    "training_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cbf5d-92c5-4de1-b0da-71f18925f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol = 'userIndex', itemCol = 'itemIndex', ratingCol = 'rating', coldStartStrategy ='drop', nonnegative = True)\n",
    "model = als.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207959e-f4b6-4d12-8ff5-a01085939b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mapping_df = indexed_df.select('asin', 'itemIndex').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations_als_spark(user_id, model, item_mapping_df, n):\n",
    "    user_index_row = indexed_df.filter(col('user_id') == user_id).select('userIndex').first()\n",
    "    if not user_index_row:\n",
    "        raise ValueError(f\"User ID {user_id} not found.\")\n",
    "    user_index = user_index_row['userIndex']\n",
    "    \n",
    "    user_df = spark.createDataFrame([(user_index,)], ['userIndex'])\n",
    "    user_recommendations = model.recommendForUserSubset(user_df, n)\n",
    "    \n",
    "    recommended_items = user_recommendations.withColumn(\"itemIndex\", F.explode(\"recommendations.itemIndex\")) \\\n",
    "        .select(\"itemIndex\").distinct() \\\n",
    "        .join(item_mapping_df, \"itemIndex\").select(\"asin\").collect()\n",
    "    \n",
    "    return [row.asin for row in recommended_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmse(model, test_df):\n",
    "    predictions = model.transform(test_df)\n",
    "    evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_for_user(user_id, actual_items_dict, recommended_items_dict):\n",
    "    actual_items = actual_items_dict.get(user_id, set())\n",
    "    recommended_items = recommended_items_dict.get(user_id, set())\n",
    "\n",
    "    num_relevant_items = len(actual_items)\n",
    "    num_recommended_items = len(recommended_items)\n",
    "    num_relevant_and_recommended = len(actual_items & recommended_items)\n",
    "\n",
    "    precision = num_relevant_and_recommended / num_recommended_items if num_recommended_items > 0 else 0.0\n",
    "    recall = num_relevant_and_recommended / num_relevant_items if num_relevant_items > 0 else 0.0\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_precision_recall(model, test_df, item_mapping_df, n):\n",
    "    user_ids = [row.user_id for row in test_df.select('user_id').distinct().collect()]\n",
    "\n",
    "    actual_items_dict = test_df.groupBy('user_id').agg(collect_set('asin').alias('actual_items')).rdd.collectAsMap()\n",
    "    recommended_items_dict = {user_id: set(get_top_n_recommendations_als_spark(user_id, model, item_mapping_df, n)) for user_id in user_ids}\n",
    "\n",
    "    results = [precision_recall_for_user(user_id, actual_items_dict, recommended_items_dict) for user_id in user_ids]\n",
    "\n",
    "    total_users = len(results)\n",
    "    avg_precision = sum(x[0] for x in results) / total_users\n",
    "    avg_recall = sum(x[1] for x in results) / total_users\n",
    "\n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e63859-bb61-4db0-95fa-01135f453669",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "user_id = 'AGI5JHRJ2PSK5BURGV762KIG2Y5A'\n",
    "top_n_recommendations = get_top_n_recommendations_als_spark(user_id, model, item_mapping_df, n)\n",
    "print(f'Top {n} recommendations for user {user_id}: {top_n_recommendations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09036187-749f-4bba-b183-c53d2f3c0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluate_rmse(model, test_df)\n",
    "print(f'Root-mean-square error = {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86c658-b1c2-4862-a3eb-9843cacd82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_precision, avg_recall = evaluate_precision_recall(model, test_df, item_mapping_df, n)\n",
    "print(f'Average Precision = {avg_precision}')\n",
    "print(f'Average Recall = {avg_recall}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

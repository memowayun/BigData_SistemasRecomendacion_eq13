{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2dd2f4-0866-4b65-b496-5a586833eeb3",
   "metadata": {},
   "source": [
    "### TC4034.10 Análisis de grandes volúmenes de datos\n",
    "\n",
    "#### Equipo 13\n",
    "\n",
    "\n",
    "* Hansel Zapiain Rodríguez (A00469031)\n",
    "* Miguel Guillermo Galindo Orozco (A01793695)\n",
    "* Francisco José Arellano Montes (A01794283)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a4743-734c-478b-9ef4-ca1f04c0bcc2",
   "metadata": {},
   "source": [
    "**9.5 Avance de proyecto 4: Sistema de Recomendación**\n",
    "   \n",
    "Junio 2024\n",
    "\n",
    "**Objetivos**\n",
    "\n",
    "\n",
    "El desarrollo de esta actividad contribuye al cumplimiento de los objetivos del Modulo 5:\n",
    "\n",
    "Aplicar algoritmos de machine learning a big data enfocado al modelado predictivo y toma de decisiones basada en datos.\n",
    "Identificar la intersección entre Big Data e Inteligencia Artificial.\n",
    "Reconocer la aplicación de algoritmos de machine learning en el análisis de Big Data\n",
    "\n",
    "**Insciones**\n",
    "\n",
    "\n",
    "onesEn esta entrega es necesario realizar un reporte donde se enlisten los siguientes aspectos:\n",
    "\n",
    "Implementación final de sistemas de recomendación. Integra la evidencia en GitHub de los algoritmos desarrollados en los avances 4.2 y/o 6.2.\n",
    "Evaluación integral del desempeño de los modelos utilizando varias métricas. Recuerda integrar la evidencia en el repositorio GitHub del equipo.\n",
    "Documentación del código base y algoritmos implementados. Entregar en el documento word/pdf en Canvas.po)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761dcc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import findspark\n",
    "import implicit\n",
    "import cudf\n",
    "import math\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit, udf, expr, row_number, collect_set\n",
    "from pyspark.sql.types import FloatType, IntegerType, ArrayType\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, Normalizer\n",
    "from pyspark.ml.linalg import Vectors, DenseVector\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb27a86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e3b4da961e490dbf42a13c1585889b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/39.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec01ec90d79c446c96674c9823de0e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/19.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95ac8df4d9d483fb3e63f63ec3e1a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/327M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264c0b6324334bdc84bc8b05f464f9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating full split:   0%|          | 0/701528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('McAuley-Lab/Amazon-Reviews-2023', 'raw_review_All_Beauty', download_mode='force_redownload', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35078d0b-f76a-4293-b71b-aca8105179bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Such a lovely scent but not overpowering.</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>1588687728923</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Works great but smells a little weird.</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>1588615855070</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes!</td>\n",
       "      <td>Smells good, feels great!</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07PNNCSP9</td>\n",
       "      <td>B097R46CSY</td>\n",
       "      <td>AE74DYR3QUGVPZJ3P7RFWBGIX7XQ</td>\n",
       "      <td>1589665266052</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Synthetic feeling</td>\n",
       "      <td>Felt synthetic</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09JS339BZ</td>\n",
       "      <td>B09JS339BZ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>1643393630220</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>Love it</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>1609322563534</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                      title  \\\n",
       "0     5.0  Such a lovely scent but not overpowering.   \n",
       "1     4.0     Works great but smells a little weird.   \n",
       "2     5.0                                       Yes!   \n",
       "3     1.0                          Synthetic feeling   \n",
       "4     5.0                                         A+   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  This spray is really nice. It smells really go...     []  B00YQ6X8EO   \n",
       "1  This product does what I need it to do, I just...     []  B081TJ8YS3   \n",
       "2                          Smells good, feels great!     []  B07PNNCSP9   \n",
       "3                                     Felt synthetic     []  B09JS339BZ   \n",
       "4                                            Love it     []  B08BZ63GMJ   \n",
       "\n",
       "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "0  B00YQ6X8EO  AGKHLEW2SOWHNMFQIJGBECAF7INQ  1588687728923             0   \n",
       "1  B081TJ8YS3  AGKHLEW2SOWHNMFQIJGBECAF7INQ  1588615855070             1   \n",
       "2  B097R46CSY  AE74DYR3QUGVPZJ3P7RFWBGIX7XQ  1589665266052             2   \n",
       "3  B09JS339BZ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1643393630220             0   \n",
       "4  B08BZ63GMJ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1609322563534             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amz = dataset['full'].to_pandas()\n",
    "df_amz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdf77eb-36d6-47b1-8dee-6f38c6dc27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.DataFrame.from_pandas(df_amz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef9314b-ac31-4f2c-862a-4a3d773683f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_result = gdf.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25c6d0-8604-4db7-a364-b412c95d1a88",
   "metadata": {},
   "source": [
    "## Pyspark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224b5e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/envs/rapids/lib/python3.11/site-packages/pyspark'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982cfff7-8a3d-4457-84b1-b540af4d4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "log4j_properties = '/app/config/log4j.properties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab6cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created: <pyspark.sql.session.SparkSession object at 0x7fb0accece90>\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('Amazon Reviews Recommender with GPU') \\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', 'true') \\\n",
    "    .config('spark.driver.memory', '32g') \\\n",
    "    .config('spark.executor.memory', '32g') \\\n",
    "    .config('spark.sql.shuffle.partitions', '500') \\\n",
    "    .config('spark.memory.fraction', '0.8') \\\n",
    "    .config('spark.memory.storageFraction', '0.5') \\\n",
    "    .config('spark.master', 'local[*]') \\\n",
    "    .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n",
    "    .config('spark.driver.extraJavaOptions', f'-Dlog4j.configuration=file:{log4j_properties}') \\\n",
    "    .config('spark.executor.extraJavaOptions', f'-Dlog4j.configuration=file:{log4j_properties}') \\\n",
    "    .config('spark.kryoserializer.buffer.max', '2024m') \\\n",
    "    .config('spark.broadcast.compress', 'true') \\\n",
    "    .config('spark.shuffle.compress', 'true') \\\n",
    "    .config('spark.shuffle.spill.compress', 'true') \\\n",
    "    .config('spark.sql.autoBroadcastJoinThreshold', '20m') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print('Spark Session Created:', spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c021dbe9-667c-4acb-bcef-9f0d4e503475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e7246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1b8de28be6ff:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Amazon Reviews Recommender with GPU</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb0accece90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0dff136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169932</th>\n",
       "      <td>5.0</td>\n",
       "      <td>EZ and great fun!</td>\n",
       "      <td>I brought these to a BBQ at our senior shindig...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07H7C4SJK</td>\n",
       "      <td>B07H7C4SJK</td>\n",
       "      <td>AFWUQ2CT6NCFBTTNI3OCWDB3CRYQ</td>\n",
       "      <td>1561426574699</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117265</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Beautiful!!</td>\n",
       "      <td>I got so many compliments with this hair.  Shi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07T9GXWLT</td>\n",
       "      <td>B07T9GXWLT</td>\n",
       "      <td>AGI5JHRJ2PSK5BURGV762KIG2Y5A</td>\n",
       "      <td>1601530836697</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30312</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>Lovely little piece!</td>\n",
       "      <td>[]</td>\n",
       "      <td>B073R5WZ4F</td>\n",
       "      <td>B073R5WZ4F</td>\n",
       "      <td>AEDSDRACFPPSWJTYBRFPMHUMHWDQ</td>\n",
       "      <td>1554611883925</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335686</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Not a gluten Free</td>\n",
       "      <td>Lovely product but it contains barley so it ir...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B071S98JST</td>\n",
       "      <td>B071S98JST</td>\n",
       "      <td>AEHQ7LKVLDNZOYSMFQFJU6DORK3Q</td>\n",
       "      <td>1681876323469</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101796</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Ehh!</td>\n",
       "      <td>A different quality of hair than what I am use...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B077BZCPSK</td>\n",
       "      <td>B077BZCPSK</td>\n",
       "      <td>AHTCO6WZEFV2UURBBZCLOKLSA64A</td>\n",
       "      <td>1562863655282</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating              title  \\\n",
       "169932     5.0  EZ and great fun!   \n",
       "117265     5.0        Beautiful!!   \n",
       "30312      5.0          Beautiful   \n",
       "335686     4.0  Not a gluten Free   \n",
       "101796     3.0               Ehh!   \n",
       "\n",
       "                                                     text images        asin  \\\n",
       "169932  I brought these to a BBQ at our senior shindig...     []  B07H7C4SJK   \n",
       "117265  I got so many compliments with this hair.  Shi...     []  B07T9GXWLT   \n",
       "30312                                Lovely little piece!     []  B073R5WZ4F   \n",
       "335686  Lovely product but it contains barley so it ir...     []  B071S98JST   \n",
       "101796  A different quality of hair than what I am use...     []  B077BZCPSK   \n",
       "\n",
       "       parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "169932  B07H7C4SJK  AFWUQ2CT6NCFBTTNI3OCWDB3CRYQ  1561426574699             2   \n",
       "117265  B07T9GXWLT  AGI5JHRJ2PSK5BURGV762KIG2Y5A  1601530836697             0   \n",
       "30312   B073R5WZ4F  AEDSDRACFPPSWJTYBRFPMHUMHWDQ  1554611883925             0   \n",
       "335686  B071S98JST  AEHQ7LKVLDNZOYSMFQFJU6DORK3Q  1681876323469             0   \n",
       "101796  B077BZCPSK  AHTCO6WZEFV2UURBBZCLOKLSA64A  1562863655282             0   \n",
       "\n",
       "        verified_purchase  \n",
       "169932               True  \n",
       "117265               True  \n",
       "30312                True  \n",
       "335686               True  \n",
       "101796               True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amz_spark = pdf_result.sample(frac = 0.10, replace = False, random_state = 1234)\n",
    "df_amz_spark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2539583",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df_amz_spark[['user_id', 'asin', 'rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a809031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = spark_df.select(col('user_id').alias('user_id'), col('asin').alias('asin'), col('rating').alias('rating'))\n",
    "\n",
    "user_indexer = StringIndexer(inputCol = 'user_id', outputCol = 'userIndex')\n",
    "item_indexer = StringIndexer(inputCol = 'asin', outputCol = 'itemIndex')\n",
    "\n",
    "indexed_df = user_indexer.fit(spark_df).transform(spark_df)\n",
    "indexed_df = item_indexer.fit(indexed_df).transform(indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d049c3-6cf3-4858-a575-cc80251dbe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|user_id                     |\n",
      "+----------------------------+\n",
      "|AFWUQ2CT6NCFBTTNI3OCWDB3CRYQ|\n",
      "|AGI5JHRJ2PSK5BURGV762KIG2Y5A|\n",
      "|AEDSDRACFPPSWJTYBRFPMHUMHWDQ|\n",
      "|AEHQ7LKVLDNZOYSMFQFJU6DORK3Q|\n",
      "|AHTCO6WZEFV2UURBBZCLOKLSA64A|\n",
      "|AE2L2THU72X2IWZWL2CR3COQVQ3A|\n",
      "|AF6PUJQU3D2RLAL6OIVLRWPTB75A|\n",
      "|AEKC3DWVNGFMF2HUGKKBAYXIZQ6A|\n",
      "|AGASM3YZF2IWIMF5LCLJOJ27DWSA|\n",
      "|AFYUWHEP53VBBYUJ4JBNRNC7NFUA|\n",
      "|AHBUU6NLVFYWQMXYHZS7O6EZAAGQ|\n",
      "|AEHE4FVFEUFFT3Z3G2CKJD2E6FXA|\n",
      "|AFLCBZENI2BIM356FE6YRQNOYHDQ|\n",
      "|AFOZH26SDYXHXA2P43KF7SOPLIHA|\n",
      "|AEFSFOWRUNELLK3BGSXUER7UHLKA|\n",
      "|AHMONSTMXMAFEGIANY6CNFIYC5EQ|\n",
      "|AG5MHGXJMURATJMQTLPVQKYP5YCA|\n",
      "|AEAVFP7USC423CPAHKI4PHXBNC7Q|\n",
      "|AG2RVJP2CMPYQY6EZ5EGEIO23S4Q|\n",
      "|AG7AHV77OZWW27JMAZ2K6GKCEL5Q|\n",
      "+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_df.select('user_id').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a3f19a-9c39-4997-9ce0-1e3736d7fc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70153"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3a8d4b-c547-459e-9925-5e89d13cbc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- userIndex: double (nullable = false)\n",
      " |-- itemIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ac399-4077-4b78-84b7-08b3f0289d21",
   "metadata": {},
   "source": [
    "## ALS (PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37c7d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_df, test_df) = indexed_df.randomSplit([0.8, 0.2])\n",
    "training_df = training_df.repartition(500).cache()\n",
    "test_df = test_df.repartition(500).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd9cbf5d-92c5-4de1-b0da-71f18925f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:14 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:14 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:15 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:16 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:17 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:17 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:18 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:18 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:18 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/06/17 02:33:18 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:18 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:18 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:18 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter = 10, regParam = 0.1, userCol = 'userIndex', itemCol = 'itemIndex', ratingCol = 'rating', coldStartStrategy = 'drop', nonnegative = True)\n",
    "model = als.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb1567ab-0a89-4139-ad47-0054eaaf4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76c02c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = userRecs.withColumn('rec_exp', F.explode('recommendations')).select('userIndex', F.col('rec_exp.itemIndex').alias('itemIndex'), F.col('rec_exp.rating').alias('predicted_rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b4d7ced-fee7-4123-bf0c-5cbc2422d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_mapping = indexed_df.select('userIndex', 'user_id').distinct()\n",
    "item_id_mapping = indexed_df.select('itemIndex', 'asin').distinct()\n",
    "\n",
    "recommendations = recommendations.join(user_id_mapping, on = 'userIndex').join(item_id_mapping, on = 'itemIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d8d3191-beb1-482a-9d27-f2ac26ba2f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:20 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:23 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:23 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------+-------+----+\n",
      "|itemIndex|userIndex|predicted_rating|user_id|asin|\n",
      "+---------+---------+----------------+-------+----+\n",
      "+---------+---------+----------------+-------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:23 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:23 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    }
   ],
   "source": [
    "user_ids = ['AFWUQ2CT6NCFBTTNI3OCWDB3CRYQ'] \n",
    "specific_user_recs = recommendations.filter(recommendations.user_id.isin(user_ids))\n",
    "specific_user_recs.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e36b2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmse(model, test_df):\n",
    "    predictions = model.transform(test_df)\n",
    "    evaluator = RegressionEvaluator(metricName = 'rmse', labelCol = 'rating', predictionCol = 'prediction')\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6a1919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k = 10):\n",
    "    total_users = predictions.select('user_id').distinct().count()\n",
    "    \n",
    "    true_positive = predictions.filter(predictions.itemIndex == predictions.trueItemIndex).count()\n",
    "    \n",
    "    recommended = predictions.count()\n",
    "    \n",
    "    precision = true_positive / recommended\n",
    "    recall = true_positive / (total_users * k) \n",
    "    \n",
    "    return total_users, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cfdc4d1-e1a8-4ad2-ad5c-973bce7ce6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(predictions, k=10):\n",
    "    def apk(actual, predicted, k):\n",
    "        if len(predicted) > k:\n",
    "            predicted = predicted[:k]\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "        for i, p in enumerate(predicted):\n",
    "            if p in actual and p not in predicted[:i]:\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i + 1.0)\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "    pred_items = predictions.groupBy('user_id').agg(F.collect_list('asin').alias('predicted_items'))\n",
    "    actual_items = test_df.groupBy('user_id').agg(F.collect_list('asin').alias('actual_items'))\n",
    "\n",
    "    pred_actual = pred_items.join(actual_items, 'user_id')\n",
    "\n",
    "    mapk = pred_actual.rdd.map(lambda row: apk(row.actual_items, row.predicted_items, k)).mean()\n",
    "    return mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7e18055-a1c3-4943-bffe-152a3604d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(predictions, k=10):\n",
    "    def dcg(actual, predicted, k):\n",
    "        dcg_score = 0.0\n",
    "        for i, p in enumerate(predicted[:k]):\n",
    "            if p in actual:\n",
    "                dcg_score += 1.0 / math.log2(i + 2)\n",
    "        return dcg_score\n",
    "\n",
    "    def idcg(actual, k):\n",
    "        idcg_score = 0.0\n",
    "        for i in range(min(len(actual), k)):\n",
    "            idcg_score += 1.0 / math.log2(i + 2)\n",
    "        return idcg_score\n",
    "\n",
    "    def ndcg(actual, predicted, k):\n",
    "        return dcg(actual, predicted, k) / idcg(actual, k)\n",
    "\n",
    "    pred_items = predictions.groupBy('user_id').agg(F.collect_list('asin').alias('predicted_items'))\n",
    "    actual_items = test_df.groupBy('user_id').agg(F.collect_list('asin').alias('actual_items'))\n",
    "\n",
    "    pred_actual = pred_items.join(actual_items, 'user_id')\n",
    "\n",
    "    ndcgk = pred_actual.rdd.map(lambda row: ndcg(row.actual_items, row.predicted_items, k)).mean()\n",
    "    return ndcgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a06f67fd-65a3-477e-ba3a-69801b65f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_at_k(predictions, k=10):\n",
    "    def reciprocal_rank(actual, predicted):\n",
    "        for i, p in enumerate(predicted[:k]):\n",
    "            if p in actual:\n",
    "                return 1.0 / (i + 1.0)\n",
    "        return 0.0\n",
    "\n",
    "    pred_items = predictions.groupBy('user_id').agg(F.collect_list('asin').alias('predicted_items'))\n",
    "    actual_items = test_df.groupBy('user_id').agg(F.collect_list('asin').alias('actual_items'))\n",
    "\n",
    "    pred_actual = pred_items.join(actual_items, 'user_id')\n",
    "\n",
    "    mrrk = pred_actual.rdd.map(lambda row: reciprocal_rank(row.actual_items, row.predicted_items)).mean()\n",
    "    return mrrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc74e9e8-1499-4e96-a855-164d3b33c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:23 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:23 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:24 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:24 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 2.885661724451385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:24 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluate_rmse(model, test_df)\n",
    "print(f'Root-mean-square error = {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1695220-aac0-4155-8879-69cf44c33fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.withColumnRenamed('itemIndex', 'trueItemIndex').withColumnRenamed('userIndex', 'trueUserIndex')\n",
    "recommendations_with_test = recommendations.join(test_df, (recommendations.user_id == test_df.user_id) & (recommendations.itemIndex == test_df.trueItemIndex), 'left').select(recommendations['*'], test_df['trueItemIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c71b9224-d20c-4bab-8784-83587d710f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:25 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:25 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:27 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:27 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:29 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:29 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:31 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:31 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:32 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:32 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:32 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:34 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:34 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:35 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:35 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:35 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:35 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:37 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:38 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:38 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:39 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:40 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:40 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:40 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:40 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:42 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:43 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:43 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:43 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:44 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "24/06/17 02:33:44 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:44 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:44 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:46 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/17 02:33:47 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/06/17 02:33:47 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users = 55259\n",
      "Average Precision = 9.048299824462984e-06\n",
      "Average Recall = 9.048299824462984e-06\n",
      "MAP at 10: 0.009095378564405114\n",
      "NDCG at 10: 0.010506213308686875\n",
      "MRR at 10: 0.009095378564405114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/17 02:33:47 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n"
     ]
    }
   ],
   "source": [
    "total_users, avg_precision, avg_recall = precision_recall_at_k(recommendations_with_test, k = 10)\n",
    "mapk = map_at_k(recommendations_with_test, k = 10)\n",
    "ndcgk = ndcg_at_k(recommendations_with_test, k = 10)\n",
    "mrrk = mrr_at_k(recommendations_with_test, k = 10)\n",
    "\n",
    "\n",
    "print(f'Total Users = {total_users}')\n",
    "print(f'Average Precision = {avg_precision}')\n",
    "print(f'Average Recall = {avg_recall}')\n",
    "print(f'MAP at 10: {mapk}')\n",
    "print(f'NDCG at 10: {ndcgk}')\n",
    "print(f'MRR at 10: {mrrk}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
